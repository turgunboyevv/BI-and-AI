{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Task 1: Read the customers table from chinook.db into a DataFrame and display the first 10 rows.\n",
    "conn = sqlite3.connect(\"chinook.db\")\n",
    "cursor = conn.cursor()\n",
    "customers_df = pd.read_sql_query(\"SELECT * FROM customers\", conn)\n",
    "print(\"Task 1: First 10 rows of the customers table:\")\n",
    "print(customers_df.head(10))\n",
    "conn.close()\n",
    "\n",
    "# Task 2: Load iris.json into a DataFrame and display the shape and column names.\n",
    "iris_df = pd.read_json(\"iris.json\")\n",
    "print(\"\\nTask 2: Shape and column names of iris dataset:\")\n",
    "print(\"Shape:\", iris_df.shape)\n",
    "print(\"Columns:\", iris_df.columns.tolist())\n",
    "\n",
    "# Task 3: Load titanic.xlsx into a DataFrame and display the first 5 rows.\n",
    "titanic_df = pd.read_excel(\"titanic.xlsx\")\n",
    "print(\"\\nTask 3: First 5 rows of Titanic dataset:\")\n",
    "print(titanic_df.head())\n",
    "\n",
    "# Task 4: Read the Flights Parquet file into a DataFrame and summarize it using info.\n",
    "# Note: Parquet files are a columnar storage file format optimized for use with big data.\n",
    "# They provide efficient storage and query performance for analytical workloads.\n",
    "flights_df = pd.read_parquet(\"flights.parquet\")\n",
    "print(\"\\nTask 4: Info about the Flights dataset:\")\n",
    "flights_df.info()\n",
    "\n",
    "# Task 5: Load movie.csv into a DataFrame and display a random sample of 10 rows.\n",
    "movies_df = pd.read_csv(\"movie.csv\")\n",
    "print(\"\\nTask 5: Random sample of 10 rows from Movies dataset:\")\n",
    "print(movies_df.sample(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. From the iris.json DataFrame:\n",
    "# Load the iris dataset\n",
    "iris_df = pd.read_json('iris.json')\n",
    "\n",
    "# Rename columns to lowercase\n",
    "iris_df.columns = iris_df.columns.str.lower()\n",
    "\n",
    "# Select only the 'sepal_length' and 'sepal_width' columns\n",
    "iris_selected = iris_df[['sepal_length', 'sepal_width']]\n",
    "\n",
    "# Display the iris selected DataFrame\n",
    "print(\"Iris Selected DataFrame:\")\n",
    "print(iris_selected)\n",
    "\n",
    "# 2. From the titanic.xlsx DataFrame:\n",
    "# Load the titanic dataset\n",
    "titanic_df = pd.read_excel('titanic.xlsx')\n",
    "\n",
    "# Filter rows where age is above 30\n",
    "titanic_filtered = titanic_df[titanic_df['age'] > 30]\n",
    "\n",
    "# Count the number of male and female passengers\n",
    "gender_counts = titanic_filtered['sex'].value_counts()\n",
    "\n",
    "# Display the titanic filtered DataFrame and gender counts\n",
    "print(\"\\nTitanic Filtered DataFrame:\")\n",
    "print(titanic_filtered)\n",
    "print(\"\\nGender Counts (Male/Female):\")\n",
    "print(gender_counts)\n",
    "\n",
    "# 3. From the flights.parquet file:\n",
    "# Load the flights dataset\n",
    "flights_df = pd.read_parquet('flights.parquet')\n",
    "\n",
    "# Extract the 'origin', 'dest', and 'carrier' columns\n",
    "flights_selected = flights_df[['origin', 'dest', 'carrier']]\n",
    "\n",
    "# Find the number of unique destinations\n",
    "unique_destinations = flights_df['dest'].nunique()\n",
    "\n",
    "# Display the flights selected DataFrame and number of unique destinations\n",
    "print(\"\\nFlights Selected DataFrame:\")\n",
    "print(flights_selected)\n",
    "print(f\"\\nNumber of unique destinations: {unique_destinations}\")\n",
    "\n",
    "# 4. From the movie.csv file:\n",
    "# Load the movie dataset\n",
    "movie_df = pd.read_csv('movie.csv')\n",
    "\n",
    "# Filter rows where duration is greater than 120 minutes\n",
    "movie_filtered = movie_df[movie_df['duration'] > 120]\n",
    "\n",
    "# Sort the filtered DataFrame by 'director_facebook_likes' in descending order\n",
    "movie_sorted = movie_filtered.sort_values(by='director_facebook_likes', ascending=False)\n",
    "\n",
    "# Display the sorted movie DataFrame\n",
    "print(\"\\nSorted Movie DataFrame (Duration > 120 minutes):\")\n",
    "print(movie_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. From iris.json: Calculate the mean, median, and standard deviation for each numerical column\n",
    "iris_df = pd.read_json('iris.json')\n",
    "mean_values = iris_df.mean()\n",
    "median_values = iris_df.median()\n",
    "std_values = iris_df.std()\n",
    "\n",
    "print(\"Iris Dataset - Mean values:\")\n",
    "print(mean_values)\n",
    "print(\"\\nIris Dataset - Median values:\")\n",
    "print(median_values)\n",
    "print(\"\\nIris Dataset - Standard deviation values:\")\n",
    "print(std_values)\n",
    "\n",
    "# 2. From titanic.xlsx: Find the minimum, maximum, and sum of passenger ages\n",
    "titanic_df = pd.read_excel('titanic.xlsx')\n",
    "min_age = titanic_df['age'].min()\n",
    "max_age = titanic_df['age'].max()\n",
    "sum_age = titanic_df['age'].sum()\n",
    "\n",
    "print(\"\\nTitanic Dataset - Minimum age:\", min_age)\n",
    "print(\"Titanic Dataset - Maximum age:\", max_age)\n",
    "print(\"Titanic Dataset - Sum of ages:\", sum_age)\n",
    "\n",
    "# 3. From movie.csv: Identify the director with the highest total director_facebook_likes\n",
    "movie_df = pd.read_csv('movie.csv')\n",
    "director_likes = movie_df.groupby('director')['director_facebook_likes'].sum()\n",
    "top_director = director_likes.idxmax()\n",
    "top_director_likes = director_likes.max()\n",
    "\n",
    "print(\"\\nMovie Dataset - Director with highest total director_facebook_likes:\")\n",
    "print(f\"Director: {top_director}, Likes: {top_director_likes}\")\n",
    "\n",
    "# 4. From movie.csv: Find the 5 longest movies and their respective directors\n",
    "longest_movies = movie_df[['director', 'duration']].sort_values(by='duration', ascending=False).head(5)\n",
    "\n",
    "print(\"\\nMovie Dataset - Top 5 longest movies and their directors:\")\n",
    "print(longest_movies)\n",
    "\n",
    "# 5. From flights.parquet: Check for missing values and fill missing values in a numerical column with the columnâ€™s mean\n",
    "flights_df = pd.read_parquet('flights.parquet')\n",
    "missing_values = flights_df.isnull().sum()\n",
    "flights_df_filled = flights_df.fillna(flights_df.mean())\n",
    "\n",
    "print(\"\\nFlights Dataset - Missing values per column:\")\n",
    "print(missing_values)\n",
    "\n",
    "print(\"\\nFlights Dataset - Missing values filled (with column mean):\")\n",
    "print(flights_df_filled)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
